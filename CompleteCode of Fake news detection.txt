# Pandas Helps you work with data in tables (like Excel sheets). It makes it easy to read, clean, and manipulate data.
import pandas as pd
------------------------------------------------------
#numpy Used for doing math and working with large arrays of numbers, which is useful for calculations and data analysis.
import numpy as np
-----------------------------------------------------
#Seaborn A tool for creating nice and colorful charts and graphs to help you visualize data easily.
import seaborn as sns
-------------------------------------------------------
#MatplotAnother tool for making charts and graphs, often used together with Seaborn.
import matplotlib.pyplot as plt
------------------------------------------------------
#Splits your data into two parts: one for training the machine learning model, and the other for testing how well the model performs.
from sklearn.model_selection import train_test_split
-------------------------------------------------------
#Measures how accurate the machine learning model is by comparing its predictions with the actual results.
from sklearn.metrics import accuracy_score
-------------------------------------------------------
#Gives a detailed report about how well the model is doing, including precision, recall, and F1-score.
from sklearn.metrics import classification_report
--------------------------------------------------------
#A tool that turns text (like news articles or reviews) into numbers. This helps machine learning models understand text data.
from sklearn.feature_extraction.text import TfidfVectorizer
---------------------------------------------------------
#A machine learning model used to predict categories (for example, predicting if something is fake news or real news).
from sklearn.linear_model import LogisticRegression
--------------------------------------------------------
#Another machine learning model that makes decisions based on a tree-like structure, used for classification tasks.
from sklearn.tree import DecisionTreeClassifier
--------------------------------------------------------
#A model that uses many decision trees to make better predictions.
from sklearn.ensemble import RandomForestClassifier
----------------------------------------------------------
#A model that works by adding many small decision trees to create a strong overall model. It's used for accurate classification tasks.
from sklearn.ensemble import GradientBoostingClassifier
--------------------------------------------------------------
#Used to find and manipulate text patterns (for example, removing URLs or specific characters from a text).
import re
---------------------------------------------------------------
#Provides access to special characters (like punctuation marks) so you can clean the text (e.g., remove commas or periods).
import string

----------------------------------------------------------------------------------------

#Read the CSV file with the help of pandas

fake = pd.read_csv("Fake.csv")
true = pd.read_csv("True.csv")

-----------------------------------------------------------------------------------------

#Insert the labeling in the CSV file table fake = 0 and true = 1

true['label'] = 1

fake['label'] = 0

true.head()

fake.head()

--------------------------------------------------------------------------------------------

#news = pd.concat([fake, true], axis = 0) use for merge 2 files in one fake and true

news = pd.concat([fake, true], axis = 0)

news.head()

news.tail()

news.isnull().sum()

--------------------------------------------------------------------------------------------

#news = news.drop(['title', 'subject','date'], axis = 1) use for remove 3 coloumns from data.

news = news.drop(['title', 'subject','date'], axis = 1)

news.head()

---------------------------------------------------------------------------------

#Use for reshuffle the date which will be mixed of fake and true

news = news.sample(frac = 1)

news.head()

-------------------------------------------------------------------------------------

#When you modify a DataFrame (like removing rows, filtering data, etc.), the row numbers (called index) can get messed up or be out of order. reset_index() fixes this problem by giving the DataFrame new index numbers starting from 0, 1, 2, and so on.

#Give a new indexes to data set in ascending order
news.reset_index(inplace=True)

news.head()

news.drop(['index'], axis = 1, inplace = True)

news.head()

--------------------------------------------

#Wordopt to optimized the words
#This function cleans text data by removing unnecessary elements like URLs, HTML tags, punctuation, numbers, and newline characters.


def wordopt(text):
  #convert into lowercase
  text = text.lower()
  #Remove URLs and replacce with nothing
  text = re.sub(r'https?://\S+|www\.\S+', '' ,text)

  #Remove HTML Tags
  text = re.sub(r'<.*?>', '', text)

  #Remove punctuation
  text = re.sub(r'[^\w\s]', '', text)

  #Remove digits
  text = re.sub(r'\d', '', text)

  #Remove newline Characters
  text = re.sub(r'\n', '', text)

  return text
--------------------------------------------------------------
#Apply a wordopt function and data set to remove extra space, punctuation, digits, newline Characters, URLs and HTML tags


news['text'] = news['text'].apply(wordopt)

news['text']

x = news['text']
y = news['label']

x

y

-----------------------------------------------------------------------------------------------------------------------------

"""Divide a data in 2 parts one is training and other one is testing and the test size is 0.3 means 30% of the data goes to testing"""

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3)

x_train.shape

x_test.shape

vectorization = TfidfVectorizer()

xv_train = vectorization.fit_transform(x_train)

xv_test = vectorization.transform(x_test)

xv_train

xv_test

-------------------------------------------

#LogisticRegression algorithm to trend the model

LR = LogisticRegression()

LR.fit(xv_train, y_train)

pred_lr = LR.predict(xv_test)

LR.score(xv_test, y_test)

print(classification_report(y_test, pred_lr))

------------------------------------------------------------------

##DecisionTreeClassifier algorithm to trend the model

Dtc = DecisionTreeClassifier()

Dtc.fit(xv_train, y_train)

predicted_Dtc = Dtc.predict(xv_test)

Dtc.score(xv_test, y_test)

print(classification_report(y_test, predicted_Dtc))

------------------------------------------------------------------

##RandomForestClassifier algorithm to trend the model

rfc = RandomForestClassifier()

rfc.fit(xv_train, y_train)

predicted_rfc = rfc.predict(xv_test)

rfc.score(xv_test, y_test)

print(classification_report(y_test, predicted_rfc))

----------------------------------------------------------------------
#GradientBoostingClassifier algorithm to trend the model

gbc = GradientBoostingClassifier()

gbc.fit(xv_train, y_train)

predicted_gbc = gbc.predict(xv_test)

gbc.score(xv_test, y_test)

print(classification_report(y_test,predicted_gbc))
-------------------------------------------------------------------------

#Check the output label on the basis of 0 or 1

def output_label(n):
  if n == 0:
    return "It is a fake news"
  elif n == 1:
    return "It is a true news"
  else:
    return "Invalid news"

#Check the news is valid or not

def is_valid_news(news):
    """Check if the input news is valid."""
    if len(news.split()) < 3:  # Too short
        return False
    return True

#Check the news is present in data set or not

def is_news_presentInDS(news, new_data):
  if news not in new_data["text"].values:
    print("Invalid news ❌. This news is not present in the dataset.")
    return False
  else:
    return True

#Manual testing performance

def manual_testing(news):
  testing_news = {"text": [news]}
  new_def_test = pd.DataFrame(testing_news)
  new_def_test["text"] = new_def_test["text"].apply(wordopt)
  new_x_test = new_def_test["text"]
  new_xv_test = vectorization.transform(new_x_test)
  pred_lr = LR.predict(new_xv_test)
  predicted_Dtc = Dtc.predict(new_xv_test)
  predicted_rfc = rfc.predict(new_xv_test)
  predicted_gbc = gbc.predict(new_xv_test)

  # 4️⃣ Confidence Check
  prob_lr = max(LR.predict_proba(new_xv_test)[0])  # max probability for LR
  prob_dtc = max(Dtc.predict_proba(new_xv_test)[0])  # max probability for DTC
  prob_rfc = max(rfc.predict_proba(new_xv_test)[0])  # max probability for RFC
  prob_gbc = max(gbc.predict_proba(new_xv_test)[0])  # max probability for GBC

  #Check the probability of news
  if prob_lr < 0.6 and prob_dtc < 0.6 and prob_rfc < 0.6 and prob_gbc < 0.6:
    return print("❌ Invalid news. The model is not confident about this input.")

  return print("\n\n✅ LR Prediction: {} \n✅ DTC Prediction: {} \n✅ RFC Prediction: {} \n✅ GBC Prediction: {}".format(
      output_label(pred_lr[0]),
      output_label(predicted_Dtc[0]),
      output_label(predicted_rfc[0]),
      output_label(predicted_gbc[0])
  ))

#Run 

while True:
  new_data = pd.concat([fake, true], axis = 0)
  news_article = str(input("Put your news here! \n"))
  if news_article == 'Exit' or news_article == 'exit' or news_article == 'e':
    print('Thank you for using')
    break
  elif not is_valid_news(news_article):
    print("❌ Invalid news. The input does not look like valid news text.")
  elif is_news_presentInDS(news_article, new_one):
    manual_testing(news_article)
  else:
    print('Invalid input\n')
  print('Type Exit or e for end\n')